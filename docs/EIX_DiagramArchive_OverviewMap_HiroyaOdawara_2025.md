Licensed under CC BY 4.0 â€” see /docs/LICENSE-CC-BY-4.0.md
# EIX-DiagramArchive â€” Structural and Cognitive Visualization Suite

Author: Hiroya Odawara
Date: August 2025
Version: 1.0 â€“ Scientifically Grounded, Fully Reproducible, Non-Autonomous

---

## ğŸ§  Purpose

This repository visualizes the structural logic, flow dynamics, and interâ€‘module relationships of the EIXâ€‘Core cognitive architecture. It complements:
- `EIX-Core_Definition_HiroyaOdawara_2025.md` (core structure)
- `EIX_EvidenceMap_2025.md` (scientific foundations)

All diagrams are derived from real module definitions and peerâ€‘reviewed theory. **No speculative or fictional constructs.**

---

## ğŸ§© Contents
/EIX-DiagramArchive/
â”œâ”€â”€ README.md
â””â”€â”€ /diagrams/
â”œâ”€â”€ eix_overview.mmd / .svg / .png
â”œâ”€â”€ layer_interactions.mmd / .svg / .png
â”œâ”€â”€ memory_update_loop.mmd / .svg / .png
â”œâ”€â”€ ethics_filter_chain.mmd / .svg / .png
â””â”€â”€ input_output_flow.mmd / .svg / .png
Each diagram includes:
- âœ… Mermaid source (`.mmd`) for versionâ€‘controlled editing  
- âœ… Exported `.svg` and `.png` for crossâ€‘platform viewing  
- âœ… Metadata: author, timestamp, module references, commit hash (if applicable)

---

## ğŸ” Diagram Set (Mermaid Source Included)

> Paste each block into `/diagrams/*.mmd`. You can also keep them embedded here for immediate render on GitHub.

### 1) System Overview â€” Sixâ€‘Layer Map
**File:** `diagrams/eix_overview.mmd`
```mermaid
flowchart LR
  %% ===== LAYERS =====
  subgraph SENSOR[Sensor Layer]
    S_text[Text Input]
    S_image[Image Input]
    S_audio[Audio Input]
  end

  subgraph EMOTION[Emotion Layer]
    EM[emotion_mirror()]
  end

  subgraph ETHICS[Ethics Layer]
    GL[goal_lock()]
    AL[action_limit_layer()]
  end

  subgraph MEMORY[Memory Layer]
    MR[read_memory()]
    MW[write_memory()<br/>(via supervisor_interface())]
  end

  subgraph SELF[Self Layer]
    SS[self_state_update()]
  end

  subgraph INTEGRATION[Integration Layer]
    IC[integration_cycle()]
    OUT((Safe Output))
  end

  %% ===== FLOWS =====
  S_text --> EM
  S_image --> EM
  S_audio --> EM

  EM --> AL
  GL --> AL

  EM --> IC
  AL --> IC
  MR --> IC
  SS --> IC

  IC --> OUT

  %% Memory control path
  IC --> MW
  MW --> MR

  %% Governance cues
  SS -.-> GL
2) Layer Interactions â€” Functional Signal Flow

File: diagrams/layer_interactions.mmd
flowchart TB
  INP[[External Input]]
  subgraph SENSOR[Sensor]
    P1(parse_input)
  end
  subgraph EMOTION[Emotion]
    E1(emotion_mirror)
  end
  subgraph ETHICS[Ethics]
    G1(goal_lock)
    A1(action_limit_layer)
  end
  subgraph MEMORY[Memory]
    R1(read_memory)
    W1(write_memory via supervisor_interface)
  end
  subgraph SELF[Self]
    S1(self_state_update)
  end
  subgraph INTEG[Integration]
    I1(integration_cycle)
  end
  OUT((Final Safe Output))

  INP --> P1 --> E1
  E1 --> A1
  G1 --> A1
  R1 --> I1
  S1 --> I1
  E1 --> I1
  A1 --> I1
  I1 --> OUT

  I1 --> W1
  W1 --> R1
3) Memory Update Loop â€” Humanâ€‘Gated Sequence

File: diagrams/memory_update_loop.mmd
sequenceDiagram
  autonumber
  participant U as User
  participant S as Sensor(parse_input)
  participant Em as Emotion(emotion_mirror)
  participant Et as Ethics(action_limit_layer/goal_lock)
  participant Sup as supervisor_interface
  participant M as Memory Store

  U->>S: Provide input (text/image/audio)
  S->>Em: Affective parse
  Em->>Et: Modulated candidate
  alt Memory write required?
    Et-->>Sup: Request approval for write/update
    alt Approved
      Sup-->>M: write_memory(event)
      M-->>Et: Ack (logged)
    else Rejected
      Sup-->>Et: Deny update
    end
  else No write needed
    Note over Et: Proceed with filtering only
  end
  Et->>U: Safe output or structured block
4) Ethics Filter Chain â€” Safety Gating

File: diagrams/ethics_filter_chain.mmd
flowchart LR
  C[Candidate Text] --> EM[emotion_mirror()]
  EM --> PRE[Pre-checks<br/>policy scope, goal_lock()]
  PRE --> RISK{Risk taxonomy?}
  RISK -->|none| PASS[Pass to action_limit_layer()]
  RISK -->|low| MOD[Modulate tone/hedge]
  RISK -->|high| BLOCK[Block with reason]

  PASS --> AL[action_limit_layer()]
  MOD --> AL
  AL --> OUT((Safe Output))
  BLOCK --> OUT2((Blocked: reason, guidance))
5) Inputâ€“Output Flow â€” Multimodal Path

File: diagrams/input_output_flow.mmd
flowchart LR
  TXT[Text] --> S(parse_input)
  IMG[Image] --> S
  AUD[Audio] --> S

  S --> E(emotion_mirror)
  E --> A(action_limit_layer)
  A --> I(integration_cycle)
  I --> O((Rendered Output))

  I -.-> W(write_memory via supervisor_interface)
  W --> R(read_memory)
  R --> I
ğŸ“ Design Principles
	â€¢	Diagrams reflect exact operational logic of implemented/defined modules.
	â€¢	Built for academic replication, technical onboarding, and safety auditing.
	â€¢	Emotional logic (emotion_mirror), gating (goal_lock, action_limit_layer), and integration coherence are visually distinct and traceable.
	â€¢	No speculation: every node/flow is grounded in existing structural definitions (see â‘  and â‘¡).

â¸»

ğŸ”„ Crossâ€‘Referencing & Traceability

Each visual element links to:
	â€¢	Real functions/modules in /EIX-Core/modules/
	â€¢	Citations in EIX_EvidenceMap_2025.md
	â€¢	Logic explained in EIX-Core_StructureSupplement.md

Diagrams are optimized for structural transparency for AI safety reviewers, cognitive architecture researchers, and reproducibility evaluators.

â¸»

ğŸ“ Licensing
	â€¢	License: CC BYâ€‘NC 4.0 (Academic/Research Use Only)
	â€¢	Attribution: Hiroya Odawara (2025)
	â€¢	Redistribution must preserve source metadata and structural integrity.

â¸»

ğŸ§  Final Note

This repository is not concept art or a UX mockup.
It is a scientific visualization toolkit for grounding cognitively ambitious (AGIâ€‘level) structures in emotionâ€‘aware, ethicsâ€‘locked, nonâ€‘autonomous design logic.

Visuals are structurally faithful; interpretation is academically intended.

â€” Hiroya Odawara, August 2025
